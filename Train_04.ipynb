{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/NewEncodings/blob/main/Train_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MMLearning/data/imdb/img_only"
      ],
      "metadata": {
        "id": "ajjEwSS9wP4l",
        "outputId": "f205c1cd-9c2c-43ca-caa9-13de9ad92020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MMLearning/data/imdb/img_only\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "KCfJth3zqdZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Dataset"
      ],
      "metadata": {
        "id": "27JUbagnvJK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "train_image_file_paths = []\n",
        "train_genre_labels = []\n",
        "\n",
        "train_image_folder_add = \"./train\"\n",
        "train_labels_file = \"./train_label.txt\"\n",
        "\n",
        "with open(train_labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "        image_path = os.path.join(train_image_folder_add, filename)\n",
        "        train_image_file_paths.append(image_path)\n",
        "        train_genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "SGASG2u5vIGc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_image_file_paths)"
      ],
      "metadata": {
        "id": "aVDEkUt8SEY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd672dda-c65e-4e56-89ef-494672485300"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15552"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "label_counts = defaultdict(int)\n",
        "\n",
        "for labels in train_genre_labels:\n",
        "    for label in labels:\n",
        "        label_counts[label] += 1"
      ],
      "metadata": {
        "id": "YF6Tgrj3F6Rc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts"
      ],
      "metadata": {
        "id": "fIpNexHFH5-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a360b58f-fa86-4455-b1b7-40d3d61777f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'Crime': 2293,\n",
              "             'Drama': 8424,\n",
              "             'Thriller': 3113,\n",
              "             'Action': 2155,\n",
              "             'Comedy': 5108,\n",
              "             'Romance': 3226,\n",
              "             'Documentary': 1234,\n",
              "             'Short': 281,\n",
              "             'Mystery': 1231,\n",
              "             'History': 680,\n",
              "             'Family': 978,\n",
              "             'Adventure': 1611,\n",
              "             'Fantasy': 1162,\n",
              "             'Sci-Fi': 1212,\n",
              "             'Western': 423,\n",
              "             'Horror': 1603,\n",
              "             'Sport': 379,\n",
              "             'War': 806,\n",
              "             'Music': 634,\n",
              "             'Musical': 503,\n",
              "             'Animation': 586,\n",
              "             'Biography': 788,\n",
              "             'Film-Noir': 202,\n",
              "             'News': 39,\n",
              "             'Talk-Show': 2,\n",
              "             'Reality-TV': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the defaultdict into a list of tuples\n",
        "label_count_list = [(label, count) for label, count in label_counts.items()]\n",
        "\n",
        "# Sort the list of tuples based on counts in descending order\n",
        "sorted_label_count_list = sorted(label_count_list, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display the sorted list\n",
        "for label, count in sorted_label_count_list:\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "print(\"Total Labels: \", len(label_count_list))"
      ],
      "metadata": {
        "id": "rzB9k8aeF6cH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad8aa54-4391-412d-baa2-f137a8659765"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drama: 8424\n",
            "Comedy: 5108\n",
            "Romance: 3226\n",
            "Thriller: 3113\n",
            "Crime: 2293\n",
            "Action: 2155\n",
            "Adventure: 1611\n",
            "Horror: 1603\n",
            "Documentary: 1234\n",
            "Mystery: 1231\n",
            "Sci-Fi: 1212\n",
            "Fantasy: 1162\n",
            "Family: 978\n",
            "War: 806\n",
            "Biography: 788\n",
            "History: 680\n",
            "Music: 634\n",
            "Animation: 586\n",
            "Musical: 503\n",
            "Western: 423\n",
            "Sport: 379\n",
            "Short: 281\n",
            "Film-Noir: 202\n",
            "News: 39\n",
            "Talk-Show: 2\n",
            "Reality-TV: 1\n",
            "Total Labels:  26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_label_count = 40\n",
        "valid_labels = [label for label, count in label_counts.items() if count >= min_label_count]\n",
        "valid_labels = sorted(list(valid_labels))"
      ],
      "metadata": {
        "id": "kEakjRS5F_bd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_labels, len(valid_labels)"
      ],
      "metadata": {
        "id": "elYCUFKfGCjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "930b87db-5056-417a-8d1d-bd75134a730b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Action',\n",
              "  'Adventure',\n",
              "  'Animation',\n",
              "  'Biography',\n",
              "  'Comedy',\n",
              "  'Crime',\n",
              "  'Documentary',\n",
              "  'Drama',\n",
              "  'Family',\n",
              "  'Fantasy',\n",
              "  'Film-Noir',\n",
              "  'History',\n",
              "  'Horror',\n",
              "  'Music',\n",
              "  'Musical',\n",
              "  'Mystery',\n",
              "  'Romance',\n",
              "  'Sci-Fi',\n",
              "  'Short',\n",
              "  'Sport',\n",
              "  'Thriller',\n",
              "  'War',\n",
              "  'Western'],\n",
              " 23)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(valid_labels)\n",
        "label2id = {label: str(i) for i, label in enumerate(valid_labels)}\n",
        "id2label = {str(i): label for i, label in enumerate(valid_labels)}"
      ],
      "metadata": {
        "id": "3erAiX-pv1PV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "id": "IYSgaj2cwKDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6514d590-752b-4ada-bbe8-143158f1d47e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 'Action',\n",
              " '1': 'Adventure',\n",
              " '2': 'Animation',\n",
              " '3': 'Biography',\n",
              " '4': 'Comedy',\n",
              " '5': 'Crime',\n",
              " '6': 'Documentary',\n",
              " '7': 'Drama',\n",
              " '8': 'Family',\n",
              " '9': 'Fantasy',\n",
              " '10': 'Film-Noir',\n",
              " '11': 'History',\n",
              " '12': 'Horror',\n",
              " '13': 'Music',\n",
              " '14': 'Musical',\n",
              " '15': 'Mystery',\n",
              " '16': 'Romance',\n",
              " '17': 'Sci-Fi',\n",
              " '18': 'Short',\n",
              " '19': 'Sport',\n",
              " '20': 'Thriller',\n",
              " '21': 'War',\n",
              " '22': 'Western'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels"
      ],
      "metadata": {
        "id": "TX4BGI9_wNfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd8fb0a-2a4f-4a3c-d244-75ea5d2eb72b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_multi_hot_labels = []\n",
        "\n",
        "for labels in train_genre_labels:\n",
        "    multi_hot = [1 if label in labels else 0 for label in valid_labels]\n",
        "    train_multi_hot_labels.append(multi_hot)"
      ],
      "metadata": {
        "id": "fkFtTj2FvWpD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_multi_hot_labels[0]"
      ],
      "metadata": {
        "id": "qEDvj2BJIKsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc3ec65-3843-4938-c78a-9e0d574e01c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_genre_labels[0]"
      ],
      "metadata": {
        "id": "sRFZ9Z9rIOSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf734e75-9dcb-4070-e767-e69250862d66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Crime', 'Drama', 'Thriller']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Dataset"
      ],
      "metadata": {
        "id": "5PZTetjHFJv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "image_file_paths = []\n",
        "genre_labels = []\n",
        "\n",
        "image_folder_add = \"./test\"\n",
        "labels_file = './test_label.txt'\n",
        "\n",
        "with open(labels_file, 'r') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split('|')\n",
        "        filename = parts[0].strip()\n",
        "        labels = parts[1].strip().split(', ')  # Split labels by comma and remove leading/trailing spaces\n",
        "        image_path = os.path.join(image_folder_add, filename)\n",
        "        image_file_paths.append(image_path)\n",
        "        genre_labels.append(labels)"
      ],
      "metadata": {
        "id": "AA5mDiCVFMDb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(image_file_paths)"
      ],
      "metadata": {
        "id": "ZL0rp0CzIbzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465f44f7-ff8e-481d-f4d2-e15c97fc47e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7799"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_file_paths[0:10]"
      ],
      "metadata": {
        "id": "8vxqITtzTdSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af24f77d-f341-44c9-ec63-b46fe4731ddc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./test/0078718_4.png',\n",
              " './test/0089003_4.png',\n",
              " './test/0098136_4.png',\n",
              " './test/0057693_4.png',\n",
              " './test/0385330_4.png',\n",
              " './test/0096487_4.png',\n",
              " './test/1220553_4.png',\n",
              " './test/1341764_4.png',\n",
              " './test/0882969_4.png',\n",
              " './test/0119918_4.png']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from collections import defaultdict\n",
        "\n",
        "# label_counts = defaultdict(int)\n",
        "\n",
        "# for labels in genre_labels:\n",
        "#     for label in labels:\n",
        "#         label_counts[label] += 1"
      ],
      "metadata": {
        "id": "0JN9GGSfGcR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label_counts"
      ],
      "metadata": {
        "id": "uE1LswS-Gh5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label_count_list = [(label, count) for label, count in label_counts.items()]\n",
        "# sorted_label_count_list = sorted(label_count_list, key=lambda x: x[1], reverse=True)\n",
        "# for label, count in sorted_label_count_list:\n",
        "#     print(f\"{label}: {count}\")\n",
        "# print(\"Total Labels: \", len(label_count_list))"
      ],
      "metadata": {
        "id": "jaUebffvJFvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_hot_labels = []\n",
        "\n",
        "for labels in genre_labels:\n",
        "    multi_hot = [1 if label in labels else 0 for label in valid_labels]\n",
        "    multi_hot_labels.append(multi_hot)"
      ],
      "metadata": {
        "id": "11mF79hnFNBW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Datasets"
      ],
      "metadata": {
        "id": "wPeiQ6yyvNOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers evaluate datasets\n",
        "from datasets import Dataset\n",
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import ViTImageProcessor, ViTForImageClassification\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "G9Nsa_BDrGNE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = {'image': train_image_file_paths, 'label': train_multi_hot_labels}\n",
        "ds_train = Dataset.from_dict(train_data)\n",
        "\n",
        "val_data = {'image': image_file_paths, 'label': multi_hot_labels}\n",
        "ds_val = Dataset.from_dict(val_data)"
      ],
      "metadata": {
        "id": "a4mLnUT7qd5l"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train"
      ],
      "metadata": {
        "id": "3SjM0TVurJGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9539adf2-6192-42ce-e84e-9ea85f60eb42"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 15552\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val"
      ],
      "metadata": {
        "id": "O8mdfwrqwykE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0737c5ce-c242-4dda-ac89-05b133ea5ed9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 7799\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def filter_function(example):\n",
        "    filename = example[\"image\"]\n",
        "    return not (filename.endswith(\"_1.png\") or filename.endswith(\"_2.png\"))"
      ],
      "metadata": {
        "id": "j8kynSG3dJ2B"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val = ds_val.filter(filter_function)"
      ],
      "metadata": {
        "id": "qhNKgZdzdMWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_val"
      ],
      "metadata": {
        "id": "hrUWaxleepOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960807dc-a5df-40c1-d3ad-9e347637fba6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 7799\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train['image'][0], ds_val['image'][0], ds_train['image'][1], ds_val['image'][1]"
      ],
      "metadata": {
        "id": "R5kP5p4_r008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770d4240-0e48-4110-de8e-f2bb5c8f3e26"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./train/0106714_4.png',\n",
              " './test/0078718_4.png',\n",
              " './train/0204504_4.png',\n",
              " './test/0089003_4.png')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# labels = ds.features[\"label\"]\n",
        "labels = valid_labels\n",
        "labels"
      ],
      "metadata": {
        "id": "iZAsVZXkrMHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214a8abf-8d09-438a-e7a0-b2e7e4d1e20b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Action',\n",
              " 'Adventure',\n",
              " 'Animation',\n",
              " 'Biography',\n",
              " 'Comedy',\n",
              " 'Crime',\n",
              " 'Documentary',\n",
              " 'Drama',\n",
              " 'Family',\n",
              " 'Fantasy',\n",
              " 'Film-Noir',\n",
              " 'History',\n",
              " 'Horror',\n",
              " 'Music',\n",
              " 'Musical',\n",
              " 'Mystery',\n",
              " 'Romance',\n",
              " 'Sci-Fi',\n",
              " 'Short',\n",
              " 'Sport',\n",
              " 'Thriller',\n",
              " 'War',\n",
              " 'Western']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Model"
      ],
      "metadata": {
        "id": "ac-q2lZhuxBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "id": "T1YZ7kVesVM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279f2b38-73fd-419a-f3d7-627710123d38"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/vit-base-patch16-224\"\n",
        "image_processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "model = ViTForImageClassification.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "qXK14nDosWFW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image as pil\n",
        "\n",
        "def transform(examples):\n",
        "  # inputs = image_processor([Image.open(img).convert(\"RGB\") for img in examples[\"image\"]], return_tensors=\"pt\")\n",
        "  inputs = image_processor([pil.open(img).convert(\"RGB\") for img in examples[\"image\"]], return_tensors=\"pt\")\n",
        "  inputs[\"labels\"] = examples[\"label\"]\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "bpeUOPS2v_qC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ds_train.with_transform(transform)\n",
        "val_dataset = ds_val.with_transform(transform)"
      ],
      "metadata": {
        "id": "DZUEGqDlwEZ-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "WgMgw6nswEo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55546d09-372c-425b-831e-2f0626001743"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 15552\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "id": "2cC5DlJQxNzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439da352-e7b5-4ce2-bdd1-178f5e6d2191"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['image', 'label'],\n",
              "    num_rows: 7799\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_dataset[0]\n",
        "# img = sample[\"pixel_values\"]\n",
        "# filename = os.path.basename(img.filename)\n",
        "# print(f\"File Name: {filename}\")"
      ],
      "metadata": {
        "id": "Yu09sABJUxNB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "id": "u9Yfq17FYtIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d0f875-8956-4094-e858-28b5ec6d3174"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pixel_values': tensor([[[-0.1529, -0.6000, -0.5765,  ..., -0.6078, -0.6078, -0.1451],\n",
              "          [-0.2471, -0.9765, -0.9686,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          [-0.1529, -0.9686, -1.0000,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          ...,\n",
              "          [-0.2078, -0.9843, -0.9765,  ..., -0.9922, -0.9922, -0.2000],\n",
              "          [-0.2235, -0.9765, -0.9922,  ..., -0.9922, -0.9922, -0.2078],\n",
              "          [-0.1373, -0.6000, -0.5686,  ..., -0.6078, -0.6078, -0.1529]],\n",
              " \n",
              "         [[-0.1529, -0.6000, -0.5765,  ..., -0.6078, -0.6078, -0.1451],\n",
              "          [-0.2471, -0.9765, -0.9686,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          [-0.1529, -0.9686, -1.0000,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          ...,\n",
              "          [-0.2078, -0.9843, -0.9765,  ..., -0.9922, -0.9922, -0.2000],\n",
              "          [-0.2235, -0.9765, -0.9922,  ..., -0.9922, -0.9922, -0.2078],\n",
              "          [-0.1373, -0.6000, -0.5686,  ..., -0.6078, -0.6078, -0.1529]],\n",
              " \n",
              "         [[-0.1529, -0.6000, -0.5765,  ..., -0.6078, -0.6078, -0.1451],\n",
              "          [-0.2471, -0.9765, -0.9686,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          [-0.1529, -0.9686, -1.0000,  ..., -1.0000, -1.0000, -0.2000],\n",
              "          ...,\n",
              "          [-0.2078, -0.9843, -0.9765,  ..., -0.9922, -0.9922, -0.2000],\n",
              "          [-0.2235, -0.9765, -0.9922,  ..., -0.9922, -0.9922, -0.2078],\n",
              "          [-0.1373, -0.6000, -0.5686,  ..., -0.6078, -0.6078, -0.1529]]]),\n",
              " 'labels': [0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0]}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in train_dataset:\n",
        "  print(item['pixel_values'].shape)\n",
        "  print(item[\"labels\"])\n",
        "  break"
      ],
      "metadata": {
        "id": "GMi1dn5qzHn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff517ecb-11ee-4268-dc24-c9be729af9ca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def collate_fn(batch):\n",
        "  return {\n",
        "      \"pixel_values\": torch.stack([x[\"pixel_values\"] for x in batch]),\n",
        "      \"labels\": torch.tensor([x[\"labels\"] for x in batch]),\n",
        "  }"
      ],
      "metadata": {
        "id": "6J-LWUv_wE48"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attach Final Layer to Model"
      ],
      "metadata": {
        "id": "nNN2igTOxdjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the ViT model\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels= len(valid_labels),\n",
        "    label2id = {label: str(i) for i, label in enumerate(valid_labels)},\n",
        "    id2label = {str(i): label for i, label in enumerate(valid_labels)},\n",
        "    problem_type = \"multi_label_classification\",\n",
        "    ignore_mismatched_sizes=True,\n",
        ")\n",
        "print(model)"
      ],
      "metadata": {
        "id": "ge9TkjxDvU7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45428eb-5ddd-4adc-a6f7-780b7fd6e264"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([23]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([23, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViTForImageClassification(\n",
            "  (vit): ViTModel(\n",
            "    (embeddings): ViTEmbeddings(\n",
            "      (patch_embeddings): ViTPatchEmbeddings(\n",
            "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "      )\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (encoder): ViTEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x ViTLayer(\n",
            "          (attention): ViTAttention(\n",
            "            (attention): ViTSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (output): ViTSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): ViTIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): ViTOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=768, out_features=23, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Hyperparameters"
      ],
      "metadata": {
        "id": "mNzrUMBDvAps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "QSaA0l0kvfD1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_loader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
        "valid_dataset_loader = DataLoader(val_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "H9a305Thv487"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "pDTtvcPav0r-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"/content/MMLearning/data/Models/Model-04\"\n",
        "summary_writer = SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "0u-AcYYPBCIq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "qxzkS9aDBEP6"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train_steps = num_epochs * len(train_dataset_loader)\n",
        "n_valid_steps = len(valid_dataset_loader)\n",
        "current_step = 0"
      ],
      "metadata": {
        "id": "dbdQh7a9BMQS"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train_steps , n_valid_steps"
      ],
      "metadata": {
        "id": "0zupZcnNxti1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f4e914-04e8-4543-a627-6c501f588117"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12150, 244)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging, eval & save steps\n",
        "save_steps = 1000"
      ],
      "metadata": {
        "id": "aS9zwwA3BXUa"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def compute_metrics(eval_pred):\n",
        "#   accuracy_score = accuracy.compute(predictions=eval_pred.predictions, references=eval_pred.label_ids)\n",
        "#   f1_score = f1.compute(predictions=eval_pred.predictions, references=eval_pred.label_ids, average=\"macro\")\n",
        "#   return {**accuracy_score, **f1_score}"
      ],
      "metadata": {
        "id": "f7H1EL2TBVPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    # progress_bar = tqdm(range(current_step, n_train_steps), \"Training\", dynamic_ncols=True, ncols=80)\n",
        "\n",
        "    for batch in train_dataset_loader:\n",
        "      if (current_step+1) % save_steps == 0:\n",
        "        print()\n",
        "        print(f\"Validation at step {current_step}...\")\n",
        "        print()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        predictions, labels = [], []\n",
        "        valid_loss = 0\n",
        "\n",
        "        for batch in valid_dataset_loader:\n",
        "            pixel_values = batch[\"pixel_values\"].to(device)\n",
        "            label_ids = batch[\"labels\"].to(device).float()\n",
        "\n",
        "            outputs = model(pixel_values=pixel_values, labels=label_ids)\n",
        "\n",
        "            loss = outputs.loss\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            logits = outputs.logits.detach().cpu()\n",
        "\n",
        "            # predictions.extend((logits > 0.5).int().cpu().numpy())\n",
        "            predictions.extend(F.sigmoid(logits).cpu().numpy())\n",
        "            labels.extend(label_ids.int().cpu().numpy())\n",
        "\n",
        "        # eval_prediction = EvalPrediction(predictions=predictions, label_ids=labels)\n",
        "        # metrics = compute_metrics(eval_prediction)\n",
        "        print()\n",
        "        print(f\"Epoch: {epoch}, Step: {current_step}, Train Loss: {train_loss / save_steps:.4f}, \" +\n",
        "              f\"Valid Loss: {valid_loss / n_valid_steps:.4f}\") # , Accuracy: {metrics['accuracy']}, \" + f\"F1 Score: {metrics['f1']}\")\n",
        "        print()\n",
        "\n",
        "        # summary_writer.add_scalar(\"valid_loss\", valid_loss / n_valid_steps, global_step=current_step)\n",
        "        # summary_writer.add_scalar(\"accuracy\", metrics[\"accuracy\"], global_step=current_step)\n",
        "        # summary_writer.add_scalar(\"f1\", metrics[\"f1\"], global_step=current_step)\n",
        "\n",
        "        model.save_pretrained(f\"/content/MMLearning/data/Models/checkpoint-{current_step}\")\n",
        "        # image_processor.save_pretrained(f\"/content/Model-04/checkpoint-{current_step}\")\n",
        "\n",
        "        predictions = np.array(predictions)\n",
        "        threshold = 0.5\n",
        "        predictions = (predictions > threshold).astype(int)\n",
        "\n",
        "        # accuracy = accuracy_score(labels, predictions)\n",
        "        # precision = precision_score(labels, predictions, average='macro')\n",
        "        # recall = recall_score(labels, predictions, average='macro')\n",
        "        f1 = f1_score(labels, predictions, average='macro')\n",
        "\n",
        "        # print(f\"Accuracy: {accuracy}\")\n",
        "        # print(f\"Precision: {precision}\")\n",
        "        # print(f\"Recall: {recall}\")\n",
        "        print(f\"F1-Score: {f1}\")\n",
        "        # print(classification_report(labels, predictions))\n",
        "\n",
        "        model.train()\n",
        "        train_loss, valid_loss = 0, 0\n",
        "\n",
        "      pixel_values = batch[\"pixel_values\"].to(device)\n",
        "      labels = batch[\"labels\"].to(device).float()\n",
        "\n",
        "      outputs = model(pixel_values=pixel_values, labels=labels)\n",
        "\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_v = loss.item()\n",
        "      train_loss += loss_v\n",
        "\n",
        "      current_step += 1\n",
        "      # progress_bar.update(1)\n",
        "      summary_writer.add_scalar(\"train_loss\", loss_v, global_step=current_step)"
      ],
      "metadata": {
        "id": "PXHxhHIqCGR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9152644-3ae9-4e0e-c91c-b04d9d8bc9f7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation at step 999...\n",
            "\n",
            "\n",
            "Epoch: 2, Step: 999, Train Loss: 0.0065, Valid Loss: 0.2453\n",
            "\n",
            "F1-Score: 0.16860153944337183\n",
            "\n",
            "Validation at step 1999...\n",
            "\n",
            "\n",
            "Epoch: 4, Step: 1999, Train Loss: 0.0107, Valid Loss: 0.2387\n",
            "\n",
            "F1-Score: 0.22147991713240314\n",
            "\n",
            "Validation at step 2999...\n",
            "\n",
            "\n",
            "Epoch: 6, Step: 2999, Train Loss: 0.0125, Valid Loss: 0.2458\n",
            "\n",
            "F1-Score: 0.24333986081301945\n",
            "\n",
            "Validation at step 3999...\n",
            "\n",
            "\n",
            "Epoch: 8, Step: 3999, Train Loss: 0.0121, Valid Loss: 0.2608\n",
            "\n",
            "F1-Score: 0.2594438118517035\n",
            "\n",
            "Validation at step 4999...\n",
            "\n",
            "\n",
            "Epoch: 10, Step: 4999, Train Loss: 0.0099, Valid Loss: 0.2845\n",
            "\n",
            "F1-Score: 0.2604503760292427\n",
            "\n",
            "Validation at step 5999...\n",
            "\n",
            "\n",
            "Epoch: 12, Step: 5999, Train Loss: 0.0078, Valid Loss: 0.3093\n",
            "\n",
            "F1-Score: 0.269369792399177\n",
            "\n",
            "Validation at step 6999...\n",
            "\n",
            "\n",
            "Epoch: 14, Step: 6999, Train Loss: 0.0058, Valid Loss: 0.3376\n",
            "\n",
            "F1-Score: 0.26866408712627476\n",
            "\n",
            "Validation at step 7999...\n",
            "\n",
            "\n",
            "Epoch: 16, Step: 7999, Train Loss: 0.0042, Valid Loss: 0.3652\n",
            "\n",
            "F1-Score: 0.2690132589318764\n",
            "\n",
            "Validation at step 8999...\n",
            "\n",
            "\n",
            "Epoch: 18, Step: 8999, Train Loss: 0.0031, Valid Loss: 0.3933\n",
            "\n",
            "F1-Score: 0.27455089014669354\n",
            "\n",
            "Validation at step 9999...\n",
            "\n",
            "\n",
            "Epoch: 20, Step: 9999, Train Loss: 0.0022, Valid Loss: 0.4266\n",
            "\n",
            "F1-Score: 0.26912279878709927\n",
            "\n",
            "Validation at step 10999...\n",
            "\n",
            "\n",
            "Epoch: 22, Step: 10999, Train Loss: 0.0016, Valid Loss: 0.4546\n",
            "\n",
            "F1-Score: 0.2680943436512926\n",
            "\n",
            "Validation at step 11999...\n",
            "\n",
            "\n",
            "Epoch: 24, Step: 11999, Train Loss: 0.0014, Valid Loss: 0.4846\n",
            "\n",
            "F1-Score: 0.26607775882341306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = ViTForImageClassification.from_pretrained(f\"/content/checkpoint-999\").to(device)\n",
        "# image_processor = ViTImageProcessor.from_pretrained(f\"/content/checkpoint-999\")"
      ],
      "metadata": {
        "id": "tHqcBHpmv2iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OM4l6La6Xqg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}