{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/NewEncodings/blob/main/Train_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MMLearning/data/food-101/flip/multimodal_img_et_flip"
      ],
      "metadata": {
        "id": "BboFDd0PeYBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8736d5ca-1bd6-46ab-f03d-5b99085c7a81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MMLearning/data/food-101/flip/multimodal_img_et_flip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H3pu3V8Tp-Q"
      },
      "outputs": [],
      "source": [
        "# Food-101 New Encoding ResNet-101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ObgVtPmABT7d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from PIL import UnidentifiedImageError\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pziXvdPgU58B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b77f3ae-d9dd-4793-c2d0-4912d33246dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00vlqtj_0TXq"
      },
      "source": [
        "# Loading Training Dataset and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "11gcKFPXGx4H"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    # transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SxiZcLMwIdP2"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.dataset = datasets.ImageFolder(data_dir)\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_lengths = self._compute_class_lengths()\n",
        "        self.num_classes = len(self.dataset.classes)\n",
        "\n",
        "    def _compute_class_lengths(self):\n",
        "        class_lengths = {cls: 0 for cls in self.classes}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.data_dir, cls)\n",
        "            if os.path.isdir(cls_dir):\n",
        "                class_lengths[cls] = len(os.listdir(cls_dir))\n",
        "\n",
        "        return class_lengths\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "\n",
        "        # Apply additional transform for the test dataset if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get_num_classes(self):\n",
        "        return self.num_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2vHn670_GyKc"
      },
      "outputs": [],
      "source": [
        "data_dir = \"./train\"\n",
        "dataset = CustomDataset(data_dir, transform=train_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S9kouQGoUpJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c16344c-deab-4c91-c84f-6567d2b8b61d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 203964\n",
            "Number of classes: 101\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of samples:\", len(dataset))\n",
        "print(\"Number of classes:\", len(dataset.classes))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "3uBNm-hsbPvJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "59G1FNZQxFOK"
      },
      "outputs": [],
      "source": [
        "data_dir1 = \"./test\"\n",
        "dataset1 = CustomDataset(data_dir1, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bl6gwC8IxRMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f44afc1-eefa-44fb-b469-4e77cadcbad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 45432\n",
            "Number of classes: 101\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of samples:\", len(dataset1))\n",
        "print(\"Number of classes:\", len(dataset1.classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "symB1iPQxTwM"
      },
      "outputs": [],
      "source": [
        "# from torchvision.datasets import ImageFolder\n",
        "# from torch.utils.data import ConcatDataset\n",
        "# combined_dataset = ConcatDataset([dataset1, dataset])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44EYL38Oxcy3"
      },
      "outputs": [],
      "source": [
        "# print(\"Number of samples:\", len(combined_dataset))\n",
        "# # print(\"Number of classes:\", len(combined_dataset.classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Cs0LSvvPGyTZ"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_data_loader = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PeyXCJavB6G8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85fc860e-8aaa-4668-bffb-6c8a48f6e4c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6374, 1420)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(data_loader), len(validation_data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsW7ms9iFQIi"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-0uV8a5pPvX"
      },
      "outputs": [],
      "source": [
        "class_lengths_dict = dataset.class_lengths\n",
        "total_sum = sum(class_lengths_dict.values())\n",
        "dict_length = len(class_lengths_dict)\n",
        "\n",
        "# Print the length\n",
        "print(\"Dictionary length:\", dict_length)\n",
        "# Print the total sum\n",
        "print(\"Total sum:\", total_sum)\n",
        "print(class_lengths_dict.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hU1isiYpR8g"
      },
      "outputs": [],
      "source": [
        "# Extract class labels and counts from the dictionary\n",
        "class_labels = list(class_lengths_dict.keys())\n",
        "class_counts = list(class_lengths_dict.values())\n",
        "\n",
        "# Create a count plot\n",
        "plt.figure(figsize=(4, 5))\n",
        "sns.barplot(x=class_labels, y=class_counts)\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.title('Count of Instances in Each Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZDNW0tS225-"
      },
      "source": [
        "# Loading ResNet-50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EH_KW2uuWpXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329577b2-e4a3-44d0-9147-2d57f478c41f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 101\n"
          ]
        }
      ],
      "source": [
        "num_classes = dataset.get_num_classes()\n",
        "print(\"Number of classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFFVJbgHN5b-"
      },
      "outputs": [],
      "source": [
        "resnet = torchvision.models.resnet101(pretrained=True)\n",
        "num_features = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(num_features, num_classes)  # num_classes is the number of classes in your dataset\n",
        "resnet.to(device)\n",
        "print(resnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH3B0YYuXbh3"
      },
      "source": [
        "# Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-16XvcH9OXyc"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nkOQcQCnGygk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "250088b2-586c-41a4-8820-f9835a648f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/30 ========> Training Loss: 3.3141  Accuracy: 0.4957\n",
            "Epoch: 2/30 ========> Training Loss: 2.2525  Accuracy: 0.5668\n",
            "Epoch: 3/30 ========> Training Loss: 1.8652  Accuracy: 0.6079\n",
            "Epoch: 4/30 ========> Training Loss: 1.5693  Accuracy: 0.6286\n",
            "Epoch: 5/30 ========> Training Loss: 1.2919  Accuracy: 0.6390\n",
            "Epoch: 6/30 ========> Training Loss: 1.0325  Accuracy: 0.6458\n",
            "Epoch: 7/30 ========> Training Loss: 0.7991  Accuracy: 0.6399\n",
            "Epoch: 8/30 ========> Training Loss: 0.6171  Accuracy: 0.6450\n",
            "Epoch: 9/30 ========> Training Loss: 0.4918  Accuracy: 0.6357\n",
            "Epoch: 10/30 ========> Training Loss: 0.4087  Accuracy: 0.6331\n",
            "Epoch: 11/30 ========> Training Loss: 0.3562  Accuracy: 0.6477\n",
            "Epoch: 12/30 ========> Training Loss: 0.3213  Accuracy: 0.6409\n",
            "Epoch: 13/30 ========> Training Loss: 0.2911  Accuracy: 0.6406\n",
            "Epoch: 14/30 ========> Training Loss: 0.2729  Accuracy: 0.6432\n",
            "Epoch: 15/30 ========> Training Loss: 0.2553  Accuracy: 0.6465\n",
            "Epoch: 16/30 ========> Training Loss: 0.2426  Accuracy: 0.6441\n",
            "Epoch: 17/30 ========> Training Loss: 0.2314  Accuracy: 0.6476\n",
            "Epoch: 18/30 ========> Training Loss: 0.2233  Accuracy: 0.6504\n",
            "Epoch: 19/30 ========> Training Loss: 0.2139  Accuracy: 0.6515\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5c67b243a26f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from keras.metrics import top_k_categorical_accuracy\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import roc_auc_score\n",
        "training_loss = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Set the model to training mode\n",
        "    resnet.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Iterate over the data loader\n",
        "    for images, labels in data_loader:\n",
        "        # Move the images and labels to the GPU if available\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = resnet(images)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the running loss\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Calculate the average loss for the epoch\n",
        "    epoch_loss = running_loss / len(data_loader.dataset)\n",
        "    training_loss.append(epoch_loss)\n",
        "    # Print the epoch loss\n",
        "    # print(f\"Epoch {epoch+1}/{num_epochs} Training Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    resnet.eval()\n",
        "\n",
        "    predicted_classes = []\n",
        "    actual_labels = []\n",
        "\n",
        "    # all_outputs = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_data_loader:\n",
        "            # Move the images and labels to the GPU if available\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = resnet(images)\n",
        "\n",
        "            # Get the predicted labels\n",
        "            _, predicted_label = torch.max(outputs, 1)\n",
        "\n",
        "            # Store the predicted and true labels\n",
        "            predicted_classes.extend(predicted_label.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "            # all_outputs.append(outputs.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(actual_labels, predicted_classes)\n",
        "    # precision = precision_score(actual_labels, predicted_classes, average='weighted')\n",
        "    # recall = recall_score(actual_labels, predicted_classes, average='weighted')\n",
        "    # f1 = f1_score(actual_labels, predicted_classes, average='weighted')\n",
        "\n",
        "    # top_5_accuracy = top_k_categorical_accuracy(actual_labels.astype('float32'), predicted_classes.astype('float32'), k=5)\n",
        "    # top_5_accuracy_value = K.eval(K.mean(top_5_accuracy))\n",
        "\n",
        "    # auroc = roc_auc_score(actual_labels, predicted_classes)\n",
        "\n",
        "    # actual_labels_tensor = torch.tensor(actual_labels)\n",
        "    # predicted_classes_tensor = torch.tensor(predicted_classes)\n",
        "    # all_outputs = np.concatenate(all_outputs, axis=0)\n",
        "    # all_outputs_tensor = torch.tensor(all_outputs)\n",
        "    # _, top5_predicted_indices = torch.topk(all_outputs_tensor, k=5, dim=1)\n",
        "    # correct_top5 = torch.any(top5_predicted_indices == actual_labels_tensor.view(-1, 1), dim=1)\n",
        "    # top5_accuracy = torch.mean(correct_top5.float()).item()\n",
        "\n",
        "    # print(\"Accuracy:\", accuracy)\n",
        "    # print(\"Precision:\", precision)\n",
        "    # print(\"Recall:\", recall)\n",
        "    # print(\"F1-score:\", f1)\n",
        "    # print(f\"Epoch: {epoch+1}/{num_epochs} ========> Training Loss: {epoch_loss:.4f}  Accuracy: {accuracy:.4f} Top-5 Accuracy: {top5_accuracy:.4f}\")\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}/{num_epochs} ========> Training Loss: {epoch_loss:.4f}  Accuracy: {accuracy:.4f}\")\n",
        "    save_dir = \"/content/MMLearning/data/Models/Model-21\"\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "    model_name = str(epoch+1) + \"_model.pth\"\n",
        "    save_path = os.path.join(save_dir, model_name)  # Specify the complete path to the model file\n",
        "    torch.save(resnet.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBQm6WUy2Mas"
      },
      "outputs": [],
      "source": [
        "# Plot the loss curve\n",
        "plt.plot(range(1, num_epochs+1), training_loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Curve')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA19HxxWkW78"
      },
      "source": [
        "# Save Best Model File to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En61iS0MncTo"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdafxfVVneqc"
      },
      "outputs": [],
      "source": [
        "# %cd /content/Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_N_X_mUngns"
      },
      "outputs": [],
      "source": [
        "# !cp 7_model.pth /content/drive/MyDrive/filename"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = './Models/Models_fused_food101/'\n",
        "load_path = os.path.join(save_dir, \"22_model (2).pth\")\n",
        "\n",
        "# Create an instance of the ResNet model\n",
        "resnet = torchvision.models.resnet101(pretrained=False)\n",
        "resnet.fc = nn.Linear(2048, 101) # Choose the number of output classses as per your model\n",
        "\n",
        "# Load the saved model parameters\n",
        "resnet.load_state_dict(torch.load(load_path))\n",
        "# resnet.load_state_dict(torch.load(load_path, map_location=torch.device('cpu')))\n",
        "\n",
        "# Set the model to evaluation mode and respective device\n",
        "resnet.eval()\n",
        "resnet.to(device)"
      ],
      "metadata": {
        "id": "Zra-F9ZKrmCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet.eval()\n",
        "\n",
        "predicted_classes = []\n",
        "actual_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in validation_data_loader:\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = resnet(images)\n",
        "        _, predicted_label = torch.max(outputs, 1)\n",
        "\n",
        "        predicted_classes.extend(predicted_label.cpu().tolist())\n",
        "        actual_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "accuracy = accuracy_score(actual_labels, predicted_classes)"
      ],
      "metadata": {
        "id": "JfaexZZgquU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "aBNr4kKIrXz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXeuyczVUMKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vsW7ms9iFQIi",
        "GZDNW0tS225-",
        "oA19HxxWkW78"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}