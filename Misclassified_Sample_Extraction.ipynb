{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadIrzam447/NewEncodings/blob/main/Misclassified_Sample_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObgVtPmABT7d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from PIL import UnidentifiedImageError\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "pziXvdPgU58B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Validation Dataset and Preprocessing"
      ],
      "metadata": {
        "id": "p3yzu25SYhKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "4ElOxuNZvqLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ValidationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.dataset = datasets.ImageFolder(data_dir, transform=val_transform)\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_lengths = self._compute_class_lengths()\n",
        "        self.samples = self.dataset.samples  # Store the file paths along with labels\n",
        "\n",
        "\n",
        "    def _compute_class_lengths(self):\n",
        "        class_lengths = {cls: 0 for cls in self.classes}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.data_dir, cls)\n",
        "            if os.path.isdir(cls_dir):\n",
        "                class_lengths[cls] = len(os.listdir(cls_dir))\n",
        "\n",
        "        return class_lengths\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "metadata": {
        "id": "ZEqVuNvcMgvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valPath = \"/content/MMLearning/data/food-101/flip/multimodal_img_et_flip/test\"\n",
        "val_dataset = ValidationDataset(valPath)"
      ],
      "metadata": {
        "id": "4UfrxOQ3sCgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "validation_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "8e-uQ6lqVhmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples:\", len(val_dataset))\n",
        "print(\"Number of classes:\", len(val_dataset.classes))"
      ],
      "metadata": {
        "id": "oShp-fOcVmYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_batches = len(validation_data_loader)\n",
        "print(\"Number of batches:\", num_batches)"
      ],
      "metadata": {
        "id": "l_2_YsDRCJL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "RbwN0R_b2tMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = '/content/MMLearning/data/Models/Model-21'\n",
        "model_name = \"fused_model.pth\"\n",
        "load_path = os.path.join(save_dir, model_name)\n",
        "\n",
        "resnet = torchvision.models.resnet101(pretrained=False)\n",
        "resnet.fc = nn.Linear(2048, 101) # Choose the number of output classses as per your model\n",
        "resnet.load_state_dict(torch.load(load_path))\n",
        "\n",
        "resnet.eval()\n",
        "resnet.to(device)"
      ],
      "metadata": {
        "id": "UeVCrdLVbb4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store misclassified samples\n",
        "misclassified_samples = []"
      ],
      "metadata": {
        "id": "loo5VFVNdweB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes = []\n",
        "actual_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (images, labels) in enumerate(validation_data_loader):\n",
        "        # Move the images and labels to the GPU if available\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = resnet(images)\n",
        "\n",
        "        # Get the predicted labels\n",
        "        _, predicted_label = torch.max(outputs, 1)\n",
        "\n",
        "        # Store the predicted and true labels\n",
        "        predicted_classes.extend(predicted_label.cpu().tolist())\n",
        "        actual_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        # Check for misclassified samples\n",
        "        misclassified_samples.extend([\n",
        "            sample for sample, pred, actual in zip(val_dataset.samples[i * batch_size:(i + 1) * batch_size], predicted_label.cpu(), labels.cpu())\n",
        "            if pred != actual\n",
        "        ])"
      ],
      "metadata": {
        "id": "QYxUnUjO7DOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(misclassified_samples)"
      ],
      "metadata": {
        "id": "falgTniXgGtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MMLearning/data/Models/Model-21\n",
        "with open(\"fused.txt\", \"w\") as file:\n",
        "    for item in misclassified_samples:\n",
        "        file.write(str(item) + \"\\n\")"
      ],
      "metadata": {
        "id": "tqHyy2Vci05i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(actual_labels, predicted_classes)\n",
        "precision = precision_score(actual_labels, predicted_classes, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_classes, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_classes, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "SiJYzy3heKgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(actual_labels, predicted_classes))"
      ],
      "metadata": {
        "id": "1PEdbnvj0vPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMLS1oL0bMJB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}